{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPU1YeTeESNszuB4noFR2dE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d98s/TrialNotebook/blob/main/Untitled14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-clip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G86gZ3JtEr_o",
        "outputId": "675664ea-4d4b-4e48-cf32-6ae23531aba9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-clip\n",
            "  Downloading openai-clip-1.0.1.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from openai-clip)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from openai-clip) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-clip) (4.65.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->openai-clip) (0.2.6)\n",
            "Building wheels for collected packages: openai-clip\n",
            "  Building wheel for openai-clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-clip: filename=openai_clip-1.0.1-py3-none-any.whl size=1368607 sha256=74ac124575ceb907fa3329294690811e8ccf2255aa31598ac34864d61bbde540\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/77/8e/8d2f862df6bf7fb4e2007062d2cbaeae49862ec7b56d041229\n",
            "Successfully built openai-clip\n",
            "Installing collected packages: ftfy, openai-clip\n",
            "Successfully installed ftfy-6.1.1 openai-clip-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import clip\n",
        "import requests\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "aqWNYpSdElK-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = torch.load('prompts.pt')"
      ],
      "metadata": {
        "id": "DBGQSVQ9EXJn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_prompts = torch.load('google_prompts.pt')"
      ],
      "metadata": {
        "id": "JzntmHIfEpZk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_prompts[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s-l8CihGyc1",
        "outputId": "a17885ad-cba0-4670-c6b6-817ad0eab80f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['A photo of a kit_fox.',\n",
              "  'A photo of a Animal.',\n",
              "  'The kit fox is a fox species that inhabits arid and semi-arid regions of the southwestern United States and northern and central Mexico. '],\n",
              " ['A photo of a English_setter.',\n",
              "  'A photo of a Dog breed.',\n",
              "  'The English Setter is a medium-size breed of dog. It is part of the setter group, which includes the red Irish Setters, Irish Red and White Setters, and black-and-tan Gordon Setters. '],\n",
              " ['A photo of a Siberian_husky.',\n",
              "  'A photo of a Dog breed.',\n",
              "  'The Siberian Husky is a medium-sized working sled dog breed. The breed belongs to the Spitz genetic family. It is recognizable by its thickly furred double coat, erect triangular ears, and distinctive markings, and is smaller than the similar-looking Alaskan Malamute.\\n'],\n",
              " ['A photo of a Australian_terrier.',\n",
              "  'A photo of a Dog breed.',\n",
              "  'The Australian Terrier is a small breed of dog of the terrier dog type. The breed was developed in Australia, although the ancestral types of dogs from which the breed descends were from Great Britain.'],\n",
              " ['A photo of a English_springer.',\n",
              "  'A photo of a Dog breed.',\n",
              "  'The English Springer is a breed of gun dog in the Spaniel group traditionally used for flushing and retrieving game. It is an affectionate, excitable breed with a typical lifespan of twelve to fourteen years. '],\n",
              " ['A photo of a grey_whale.',\n",
              "  'A photo of a Animal.',\n",
              "  'The gray whale, also known as the grey whale, gray back whale, Pacific gray whale, Korean gray whale, or California gray whale, is a baleen whale that migrates between feeding and breeding grounds yearly. '],\n",
              " ['A photo of a lesser_panda.',\n",
              "  'A photo of a Animal.',\n",
              "  'The red panda, also known as the lesser panda, is a small mammal native to the eastern Himalayas and southwestern China. It has dense reddish-brown fur with a black belly and legs, white-lined ears, a mostly white muzzle and a ringed tail. '],\n",
              " ['A photo of a Egyptian_cat.'],\n",
              " ['A photo of a ibex.',\n",
              "  'A photo of a Stock market index.',\n",
              "  \"The IBEX 35 is the benchmark stock market index of the Bolsa de Madrid, Spain's principal stock exchange. Initiated in 1992, the index is administered and calculated by Sociedad de Bolsas, a subsidiary of Bolsas y Mercados Españoles, the company which runs Spain's securities markets. \"],\n",
              " ['A photo of a Persian_cat.',\n",
              "  'A photo of a Cat breed.',\n",
              "  'The Persian cat, also known as the Persian longhair, is a long-haired breed of cat characterized by a round face and short muzzle. ']]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GN5fBOTmEIdX"
      },
      "outputs": [],
      "source": [
        "def conceptnet_related(word):\n",
        "  response = requests.get('https://api.conceptnet.io/c/en/{}'.format(word)).json()\n",
        "  ans = {'Syn' : [word.replace('_', ' ')], 'IsA' : []}\n",
        "  already_in = [word.replace('_', ' ')]\n",
        "  # print(response)\n",
        "  for res in response['edges']:\n",
        "    if res['start']['language'] == 'en':\n",
        "      if res['rel']['label'] == 'IsA':\n",
        "        if res['end']['label'] not in already_in:\n",
        "          already_in.append(res['end']['label'])\n",
        "          ans['IsA'].append(res['end']['label'])\n",
        "      if res['rel']['label'] == 'Synonym':\n",
        "        if res['start']['label'] not in already_in:\n",
        "          already_in.append(res['start']['label'])\n",
        "          ans['Syn'].append(res['start']['label'])\n",
        "  return ans"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imagenet_templates = [\n",
        "    \"itap of a {}.\",\n",
        "    \"a bad photo of the {}.\",\n",
        "    \"a origami {}.\",\n",
        "    \"a photo of the large {}.\",\n",
        "    \"a {} in a video game.\",\n",
        "    \"art of the {}.\",\n",
        "    \"a photo of the small {}.\",\n",
        "]\n",
        "template_ = 'A photo of a type of {}.'\n",
        "template_conceptnet_google_prompts = []\n",
        "for prompt, google_prompt in tqdm(zip(prompts, google_prompts)):\n",
        "  ans = conceptnet_related(prompt.split(' ')[-1][:-1].lower())\n",
        "  prompt_set = []\n",
        "  for template in imagenet_templates:\n",
        "    inner_set = []\n",
        "    for k in ans.keys():\n",
        "      if k == 'Syn':\n",
        "        for syn in ans[k]:\n",
        "          inner_set.append(template.format(syn))\n",
        "      if k == 'IsA':\n",
        "        for isa in ans[k]:\n",
        "          inner_set.append(template_.format(isa))\n",
        "    for prmpt in google_prompt[1:]:\n",
        "      if prmpt not in inner_set:\n",
        "        inner_set.append(prmpt)\n",
        "    prompt_set.append(inner_set)\n",
        "  template_conceptnet_google_prompts.append(prompt_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwGBYXjSHMLS",
        "outputId": "ac8bafce-768a-4c88-a9a6-b1493c0decc7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000it [02:46,  6.01it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "clip_model, processor = clip.load('ViT-B/32', device='cpu')\n",
        "clip_model = clip_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv3emHC-I0TZ",
        "outputId": "0b41773f-6709-4d9f-cd53-18010e091d16"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 338M/338M [00:02<00:00, 138MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template_conceptnet_google_prompt_encodings = {}\n",
        "i = 0\n",
        "with torch.no_grad():\n",
        "  for prompt_set in tqdm(template_conceptnet_google_prompts):\n",
        "    prompt_set_encoding = []\n",
        "    for prmpt in prompt_set:\n",
        "      prompt_encoding = clip_model.encode_text(clip.tokenize(prmpt, truncate=True).to('cpu'))\n",
        "      prompt_encoding = prompt_encoding / prompt_encoding.norm(dim=-1, keepdim=True)\n",
        "      prompt_set_encoding.append(prompt_encoding)\n",
        "    template_conceptnet_google_prompt_encodings[i] = prompt_set_encoding\n",
        "    i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSE5vKlRF2fF",
        "outputId": "d35a39fa-34ae-4469-a844-faa8c856cfb9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [1:03:03<00:00,  3.78s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(template_conceptnet_google_prompt_encodings, 'template_conceptnet_google_prompt_encodings.pt')"
      ],
      "metadata": {
        "id": "Almy_GpY1Mjo"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "template_conceptnet_google_prompt_encodings_attention_list = {}\n",
        "for k in tqdm(template_conceptnet_google_prompt_encodings.keys()):\n",
        "  set_encoding = []\n",
        "  for encoding in template_conceptnet_google_prompt_encodings[k]:\n",
        "    # encoding = template_conceptnet_google_prompt_encodings[k]\n",
        "    weight_score = (encoding @ encoding.t()) * 10\n",
        "    weight_score = weight_score.softmax(dim=1)\n",
        "    encoding_attention = (weight_score @ encoding)[0]\n",
        "\n",
        "    # weight_score = (encoding_attention @ encoding_attention.t()) * 100\n",
        "    # weight_score = weight_score.softmax(dim=1)\n",
        "    # encoding_attention = (weight_score @ encoding_attention)\n",
        "\n",
        "    # # encoding_attention = encoding_attention / encoding_attention.norm(dim=1,keepdim=True)\n",
        "    # # encoding_attention += encoding\n",
        "\n",
        "    # weight_score = (encoding_attention @ encoding_attention.t()) * 1000\n",
        "    # weight_score = weight_score.softmax(dim=1)\n",
        "    # encoding_attention = (weight_score @ encoding_attention)\n",
        "\n",
        "    # # encoding_attention = encoding_attention / encoding_attention.norm(dim=1,keepdim=True)\n",
        "    # # encoding_attention += encoding\n",
        "\n",
        "    # weight_score = (encoding_attention @ encoding_attention.t()) * 1000\n",
        "    # weight_score = weight_score.softmax(dim=1)\n",
        "    # encoding_attention = (weight_score @ encoding_attention)\n",
        "\n",
        "    # weight_score = (encoding_attention @ encoding_attention.t()) * 1000\n",
        "    # weight_score = weight_score.softmax(dim=1)\n",
        "    # encoding_attention = (weight_score @ encoding_attention)\n",
        "    # # encoding_attention = encoding_attention / encoding_attention.norm(dim=1,keepdim=True)\n",
        "    # # encoding_attention += encoding\n",
        "\n",
        "    # weight_score = (encoding_attention @ encoding_attention.t()) * 1000\n",
        "    # weight_score = weight_score.softmax(dim=1)\n",
        "    # encoding_attention = (weight_score @ encoding_attention)[0]\n",
        "\n",
        "    encoding_attention += encoding[0]\n",
        "    encoding_attention = encoding_attention / encoding_attention.norm()\n",
        "    set_encoding.append(encoding_attention)\n",
        "  template_conceptnet_google_prompt_encodings_attention_list[k] = set_encoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9Q7QF7MMLip",
        "outputId": "7d1cd9fe-7bd0-4340-d273-795472659e0f"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 1171.86it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# template_conceptnet_google_prompt_encodings_attention_list[0]"
      ],
      "metadata": {
        "id": "LYzWe4_nm5t9"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_conceptnet_google_prompt_encodings_attention = torch.empty((0,512))\n",
        "for k in tqdm(template_conceptnet_google_prompt_encodings_attention_list.keys()):\n",
        "  set_encoding = template_conceptnet_google_prompt_encodings_attention_list[k]\n",
        "  sum = torch.zeros((512,))\n",
        "  for encoding in set_encoding:\n",
        "    # print(encoding.shape)\n",
        "    sum += encoding\n",
        "    # print(sum)\n",
        "  sum = sum / len(set_encoding)\n",
        "  sum = sum / sum.norm()\n",
        "  template_conceptnet_google_prompt_encodings_attention = torch.cat((template_conceptnet_google_prompt_encodings_attention, sum.unsqueeze(0)), dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgtQMkbzMDCK",
        "outputId": "35ceb1c2-aae3-418c-d3a5-848c1615b348"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 4664.81it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(output, label, n, topk=(1, 5)):\n",
        "    pred = output.topk(max(topk), 1, True, True)[1].t()\n",
        "    correct = pred.eq(label.view(1, -1).expand_as(pred))\n",
        "    return (100 * float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy()) / n for k in topk)"
      ],
      "metadata": {
        "id": "Y3V70sAMGDG4"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_labels = torch.load('img_labels.pt')\n",
        "img_labels = torch.tensor(img_labels)\n",
        "processed_images = torch.load('processed_images.pt')"
      ],
      "metadata": {
        "id": "4HahPI86oDHa"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_conceptnet_google_sim_score_attention = processed_images @ template_conceptnet_google_prompt_encodings_attention.t()"
      ],
      "metadata": {
        "id": "57EHykInnmBT"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_conceptnet_google_acc_attention = accuracy(template_conceptnet_google_sim_score_attention, img_labels-1, template_conceptnet_google_sim_score_attention.shape[0])\n",
        "for a in template_conceptnet_google_acc_attention:\n",
        "  print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2eZhQdznpie",
        "outputId": "45d3d77f-2bc3-4770-c752-284c1018b3d3"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61.48264853435051\n",
            "86.05041668394212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qHRG-5UZnuDp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}